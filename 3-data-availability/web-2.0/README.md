[![banner](https://raw.githubusercontent.com/oceanprotocol/art/master/github/repo-banner%402x.png)](https://oceanprotocol.com)

# Proof of Data Availability in Web 2.0 Settings

```
name: proof of data availability (web 2.0).
type: research
status: updated draft
editor: Fang Gong <fang@oceanprotocol.com>
date: 01/31/2019
```

## 1. Introduction

Nowadays the big volumes of data are typically stored in enterprise/organization silos in Big Data Lakers, Data Warehouse solutions or similar bespoke solutions.

This data is not publicly available and typically stored in:

* Cloud Providers (mostly Amazon and Azure)
* On-premise solutions
One of the requirements to ensure the "availability" of all datasets, which facilitates the mechanisms to retreive a Proof of Availability from cloud providers (p.e Amazon S3, Microsoft Azure) or on-premise (behind a HTTP service).

Ocean must provide the mechanisms to proof that data is available in these circumstances. Also needs to facilitate the procedure to external verifiers to validate that files included in the assets are available to be consumed.

The solution must not require to move the source data to make any calculation.

In the scope of this research task, it would be necessary to detail the possible solutions to put in place and the potential integration with Ocean architecture.

## 2. Architecture

Consider the solution cannot move or modify the source data, the most straightforward approach is **challenge-response solution**. The overall architecture shown in the below:

* **Data Provider**: the data owner who provides the dataset;
* **Data Verifer**: the data verifier who verifies the availability of dataset;
* **Smart Contract**: the Keeper contract deployed on blockchain network;
* **Ocean Off-Chain Query Component**: the off-chain query module that bridges the Keeper contract with cloud storage and OceanDB:
	* resolves the DID into DDO and extract `files` attribute;
	* query the checksum of each file from cloud provider (e.g., ETag of each file in S3)
	* calculate checksum of dataset as **SHA3 Hash** of ([list of all file checksums] + name + author + license + did)
* **OceanDB**: metadata-store that contains metadata information of datasets. 
* **Cloud Provider**: the data storage infrastructure that holds the raw data files such as AWS S3 and Azure.

<img src="img/architecture.jpg" width=1000 />

**Pros:**

* simple and implementable;
* no need to move or modify the data source;
* easy to integrate with Ocean.

**Cons:**

* require off-chain component to interact with cloud providers;
* all parties shall trust cloud providers to honestly return checksums. A potential attack vector is cloud providers store all checksums and simply lookup the needed checksum to return when queried. It fails the proof of availability;
* data providers must trust Ocean off-chain query component will not access or distribute datasets illegally, because they should grant data access to Ocean for future queries;

### 2.1 Data Provider Workflow

* Data provider registers the dataset to keeper contract on-chain (i.e., DID registry);
* Data provider stores the data source in AWS S3 or Azure and publish DDO in OceanDB;
* Data provider grants the data access to Ocean off-chain component (e.g., add it into the permission registry for cloud storage access);
* When dataset is registered, on-chain DID registration transaction emits an event message including DID;
* Ocean off-chain component listens to the event message and resolves the DID into DDO with OceanDB. 
* `list of files` attribute can be extracted from DDO. 
* Ocean off-chain component queries the checksums of these files from cloud storage.
* Cloud provider returns the corresponding checksums for data files (e.g., ETag for each file in S3);
* Ocean off-chain component calculates the dataset checksum with formula and updates the on-chain contract for this dataset;
* At this time, registration of dataset is complete and dataset is ready to be purchased.

### 2.2 Data Verifier Workflow

* Data verifier needs to register himself as an eligible verifier in Keeper contract;
* Verifier needs to send query of data availability (i.e., query availability of a specific DID) to Ocean off-chain component;
* Ocean off-chain component first validates the identity of verifier with on-chain verifier registry;
* If identity validation pass, Ocean off-chain component: 
	* retrieve the on-chain checksum of dataset;
	* resolve DID into DDO;
	* extract `list of files` attribute;
	* query checksums of these files from cloud provider such as AWS S3.
* Cloud provider returns the checksums for all files;
* Ocean off-chain component calculates the dataset checksum with formula and compares it against the on-chain checksum;
* If matched, the data availability is verified and data verifier receives the confirmation;
* Otherwise, the data is either changed or unavailable at this time. Verifier will receive the notice of unavailability from the off-chain component.

## 3. Amazon S3 as Storage


### 3.1 Data Attributes 
Amazon S3 provides several different attributes of data, which can be combined to prove that data is the same and available for access. 

I did an experiment with bucket `fangocean`, which includes `data1.csv` and `subdata.csv` dataset files. In particular, `subdata.csv` is under the folder `subfolder` in the bucket. The file structure is following:


```
(bucket: fangocean)
	├── data1.csv
	└── (folder: subfolder)
	    └── subdata.csv
```

The online console looks like this:

<img src="img/console.jpg" width=1000 />

The metadata of a data file is similar to below. Clearly, each data file and folder has its own unique attributes:

<img src="img/object.jpg" width=800 />

* **ETag**: The entity tag is a hash of the object. The ETag reflects changes only to the contents of an object, not its metadata. 
	* Objects created by the PUT Object, POST Object, or Copy operation, or through the AWS Management Console, and are encrypted by SSE-S3 or plaintext, have ETags that are an MD5 digest of their object data.
	
	* Objects created by the PUT Object, POST Object, or Copy operation, or through the AWS Management Console, and are encrypted by SSE-C or SSE-KMS, have ETags that are not an MD5 digest of their object data.
	
	* If an object is created by either the Multipart Upload or Part Copy operation, the ETag is not an MD5 digest, regardless of the method of encryption.

* **Key**: The dataset name that identifies the data file inside S3 bucket.
* **Size**: The length in bytes of the data.

### 3.2 AWS S3 Experiment

Let us take the data file `subfolder/subdata.csv` as an example. The original contents of this file is:

```
1,left,Berlin
2,right,Berlin
3,middle,SF

```

If the data file is available, S3 should return the metadata information as:

```
 {
            "LastModified": "2019-02-01T00:28:15.000Z", 
            "ETag": "\"d41d8cd98f00b204e9800998ecf8427e\"", 
            "StorageClass": "STANDARD", 
            "Key": "subfolder/", 
            "Owner": {
                "DisplayName": "webaccount", 
                "ID": "a5af246e1a2d8986ddb54302d839152f27823e44e9dc73414037190634ec749c"
            }, 
            "Size": 0
        }, 
        {
            "LastModified": "2019-02-01T00:29:03.000Z", 
            "ETag": "\"997f0517b9e486de9e879e9bd0ae9be1\"", 
            "StorageClass": "STANDARD", 
            "Key": "subfolder/subdata.csv", 
            "Owner": {
                "DisplayName": "webaccount", 
                "ID": "a5af246e1a2d8986ddb54302d839152f27823e44e9dc73414037190634ec749c"
            }, 
            "Size": 41
        }
```

As an experiment, we change "Berlin" to be "Paris" in the first line:

```
1,left,Paris
2,right,Berlin
3,middle,SF
```

Note that the information of `subdata.csv` has some changes:

* "Size" is changed from 41Bytes to be 40Bytes;
* "ETag" is changed from `997f0517b9e486de9e879e9bd0ae9be1` to be `a0145a3c0f81f2f9e995ccd5024d8e94`.

**Note: ETag of folder remains the same even though the contained files had been modified.**

So, any changes on data file can be detected by comparing the "ETag" against its original records.

```
{
            "LastModified": "2019-02-01T00:28:15.000Z", 
            "ETag": "\"d41d8cd98f00b204e9800998ecf8427e\"", 
            "StorageClass": "STANDARD", 
            "Key": "subfolder/", 
            "Owner": {
                "DisplayName": "webaccount", 
                "ID": "a5af246e1a2d8986ddb54302d839152f27823e44e9dc73414037190634ec749c"
            }, 
            "Size": 0
        }, 
        {
            "LastModified": "2019-02-01T00:44:35.000Z", 
            "ETag": "\"a0145a3c0f81f2f9e995ccd5024d8e94\"", 
            "StorageClass": "STANDARD", 
            "Key": "subfolder/subdata.csv", 
            "Owner": {
                "DisplayName": "webaccount", 
                "ID": "a5af246e1a2d8986ddb54302d839152f27823e44e9dc73414037190634ec749c"
            }, 
            "Size": 40
        }
```

### 3.3 Required File Attributes in DDO

In order to retrieves metadata of a specific file in Amazon S3 without returning the file itself, the [`HEAD OBJECT`](https://docs.aws.amazon.com/AmazonS3/latest/API/RESTObjectHEAD.html) REST API shall be used. Note API caller must have READ access to the file.


#### 3.3.1 Syntax

To retrieve the metadata including ETag of a file, some information are required:

* ObjectName: the name identifies the file (as shown `Key` field in the above).
* BucketName: the unique name of bucket which includes the file object.
* authorization string: the string used to authorize the read access to the file.

The syntax of request is:

```
HEAD /ObjectName HTTP/1.1
Host: BucketName.s3.amazonaws.com
Authorization: authorization string
Date: date
```

* Sample Request: The following request returns the metadata of a specific file.

```
HEAD /my-image.jpg HTTP/1.1
Host: bucket.s3.amazonaws.com
Date: Wed, 28 Oct 2009 22:32:00 GMT
Authorization: AWS AKIAIOSFODNN7EXAMPLE:02236Q3V0RonhpaBX5sCYVf1bNRuU=
```

* Sample Response

```
HTTP/1.1 200 OK
x-amz-id-2: ef8yU9AS1ed4OpIszj7UDNEHGran
x-amz-request-id: 318BC8BC143432E5
x-amz-version-id: 3HL4kqtJlcpXroDTDmjVBH40Nrjfkd
Date: Wed, 28 Oct 2009 22:32:00 GMT
Last-Modified: Sun, 1 Jan 2006 12:00:00 GMT
ETag: "fba9dede5f27731c9771645a39863328"
Content-Length: 434234
Content-Type: text/plain
Connection: close
Server: AmazonS3
```

more details can be found in [document](https://docs.aws.amazon.com/AmazonS3/latest/API/RESTObjectHEAD.html)

#### 3.3.2 file attributes stored in DDO

Some file attributes need to be stored in DDO so that Ocean can generate the Requst Query to retrieve checksum of a specific file:

Attribute       |   Type        |   Description |
----------------|---------------|---------------|
ObjectName      |   String      |  filename or "Key" field of metadata. E.g., `data1.csv` & `subfolder/subdata.csv` |
BucketName      |   String      |  bucket name that is unique in S3. E.g., `fangocean` |

The `authorization` string can be set as a global environment variable that should not be stored in DDO.



## 4. Microsoft Azure as Storage


### 4.1 Data Attributes 

With Azure, we create a data file with operations: `ResourceGroup->Blobs->Container->File`. 

[`Blobs`](https://azure.microsoft.com/en-us/services/storage/blobs/) is REST-based object storage for unstructured data, which is under study in this research. Other choices are [`Files`](http://aka.ms/learnmore/filestorage), [`Tables`](http://aka.ms/learnmore/tablestorage), [`Queues`](http://aka.ms/learnmore/queuestorage).

The metadata information of a testing data file is:

<img src="img/azuredata.jpg" width=800 />

Similarly, each data file in Azure has its own unique attributes:

<img src="img/azurecli.jpg" width=600 />

* **Etag**: It is a fingerprint/checksum of the data file, which can be used to uniquely identify a specific file. The ETag reflects changes only to the name & contents of an file. 

* **name**: The file name that identifies the data inside Azure container.
* **contentLength**: The length in bytes of the contents.

### 4.2 Azure Experiment

The original data file `data.csv` has contents as:

```
1,left,Berlin
2,right,Paris
3,middle,SF
```

At this time, the Etag of this file is `0x8D68892AED7332B`. 

```
 {
    "content": null,
    "deleted": false,
    "metadata": null,
    "name": "data.csv",
    "properties": {
      ...
      "blobTierInferred": true,
      "blobType": "BlockBlob",
      "contentLength": 40,
      ...
      "creationTime": "2019-02-01T22:14:49+00:00",
      "deletedTime": null,
      "etag": "0x8D68892AED7332B",
      "lastModified": "2019-02-01T22:14:49+00:00",
      ...
      "serverEncrypted": true
    },
    "snapshot": null
  },
```

We change `Paris` to be `London` the second line:

```
1,left,Berlin
2,right,London
3,middle,SF
```

The Etag becomes `0x8D688972CAF7507` after we modify the data file.

```
{
    "content": null,
    "deleted": false,
    "metadata": null,
    "name": "data.csv",
    "properties": {
      ...
      "blobTierInferred": true,
      "blobType": "BlockBlob",
      "contentLength": 41,
      ...
      "creationTime": "2019-02-01T22:14:49+00:00",
      "deletedTime": null,
      "etag": "0x8D688972CAF7507",
      "lastModified": "2019-02-01T22:46:59+00:00",
      ...
      "serverEncrypted": true
    },
    "snapshot": null
  },
```


### 4.3 Required File Attributes in DDO

In order to retrieves metadata of a specific file in Azure without returning the file itself, the [`Get Blob Properties`](https://docs.microsoft.com/en-us/rest/api/storageservices/Get-Blob-Properties) REST API shall be used depends. Note API caller must have READ access to the file.


#### 4.3.1 Syntax

To retrieve the metadata including Etag of a file, some information are required:

* BlobName: the name identifies the file (as shown `name` field in the above).
* ContainerName: the unique name of bucket which includes the file object.
* Storage account: name of storage account that is authorized to access the file.

The GET and HEAD operations both retrieve metadata headers for the specified blob. These operations return headers only; they do not return a response body.

The URI syntax for retrieving metadata headers on a blob is as follows:

```
GET/HEAD https://<storageaccount>.blob.core.windows.net/<containername>/<blobname>  
```

* Sample Response

```
Response Status:  
HTTP/1.1 200 OK  

Response Headers:  
x-ms-meta-Name: myblob.txt  
x-ms-meta-DateUploaded: <date>  
x-ms-blob-type: AppendBlob  
x-ms-lease-status: unlocked  
x-ms-lease-state: available  
Content-Length: 11  
Content-Type: text/plain; charset=UTF-8  
Date: <date>  
ETag: "0x8CAE97120C1FF22"  
Accept-Ranges: bytes  
x-ms-blob-committed–block-count: 1  
x-ms-version: 2015-02-21  
Last-Modified: <date>  
Server: Windows-Azure-Blob/1.0 Microsoft-HTTPAPI/2.0  
x-ms-copy-id: 36650d67-05c9-4a24-9a7d-a2213e53caf6  
x-ms-copy-source: <url>  
x-ms-copy-status: success  
x-ms-copy-progress: 11/11  
x-ms-copy-completion-time: <date>  
```

more details can be found in [document](https://docs.microsoft.com/en-us/rest/api/storageservices/Get-Blob-Properties)

#### 4.3.2 file attributes stored in DDO

Some file attributes need to be stored in DDO so that Ocean can generate the Requst Query to retrieve checksum/Etag of a specific file:

Attribute       |   Type        |   Description |
----------------|---------------|---------------|
BlobName        |   String      |  blob name corresponding to data file or "name" field in metadata. E.g., `data.csv`|
ContainerName   |   String      |  container name that contains the data file and is unique in Azure. E.g., `fangocean` |



## 5. On-Premise Case

The solution in On-Premise Case is very similar to that in Cloud Provider case. The critical difference is the data provider who serves data on premise should response with Etag header of data file upon request.

### 5.1 Design

Data provider must config a HTTP server, which should interact with Ocean off-chain query component and consumers. To prove the data availability, the HTTP server shall response Ocean's query with Etag header, which is calculated in its local upon query. (Details in [document](https://devcenter.heroku.com/articles/increasing-application-performance-with-http-cache-headers#content-based))

<img src="img/onpremise.jpg" width=1000 />

**Pros:**

* straightforward, implementable and easy to be integrated with Ocean;
* no need to move or modify the data;
* compatible with the workflow using cloud providers (i.e., Amazon S3 and Azure).

**Cons:**

* all parties must trust data provider to be honest. 
* potential attack vector: data provider stores the Etags of files in the cache of HTTP server and returns them upon requst, even though the corresponding files had been removed from local storage.
* it becomes very difficult to detect fraudulence on data provider in this scenario.


### 5.2 file attributes stored in DDO

Some file attributes need to be stored in DDO so that Ocean can generate the Requst Query to retrieve checksum/Etag of a specific file:

Attribute       |   Type        |   Description |
----------------|---------------|---------------|
Name            |   String      | file name. E.g., `data.csv`|
Path            |   String      | relative path of data file in local storage. E.g., `data/volume1` |

The server (i.e., IP & port) and authorization information can be set as environment variables rather than attributes in DDO.

## 6. Reference

* [Amazon S3 REST API Reference](https://docs.aws.amazon.com/AmazonS3/latest/API/Welcome.html)
* [Azure REST API Reference](https://docs.microsoft.com/en-us/rest/api/storageservices/blob-service-rest-api)
* [Azure CLI Reference](https://docs.microsoft.com/en-us/cli/azure/storage?view=azure-cli-latest)
* [Data Security Privacy Availability and Integrity](http://thesai.org/Downloads/Volume7No4/Paper_64-Data_Security_Privacy_Availability_and_Integrity.pdf)
* [OEP-7 ASSET-DID](https://github.com/oceanprotocol/OEPs/tree/master/7#integrity)
* [OEP-8 ASSET-DDO](https://github.com/oceanprotocol/OEPs/tree/master/8#base-attributes)
* [Increasing Application Performance with HTTP Cache Headers](https://devcenter.heroku.com/articles/increasing-application-performance-with-http-cache-headers#content-based)
* [http cache headers](https://www.keycdn.com/blog/http-cache-headers)

## 7. License

```
Copyright 2018 Ocean Protocol Foundation

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
```

